{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9f75834",
   "metadata": {},
   "source": [
    "# Cancellation Task Feature Extraction\n",
    "This notebook extracts the following features for each participant and condition:\n",
    "1. **Omissions** (normalized error per quadrant)\n",
    "2. **Subjective epicenter** (mean x, y of all marks)\n",
    "3. **First mark** (x, y of the first mark)\n",
    "4. **Directional shifts** (sum of horizontal & vertical shifts)\n",
    "5. **Time shifts** (average time between marks by direction)\n",
    "6. **Smooth index** (deviation from optimized pathway)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "01519841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from math import asin, sqrt, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "68f58995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   participant_id  participant_group  round_index  click_time  click_x  \\\n",
       " 0               1                  1            1       1.765    220.0   \n",
       " 1               1                  1            2      29.529    826.0   \n",
       " 2               1                  1            3       2.230    468.0   \n",
       " 3               1                  1            3       3.022    346.0   \n",
       " 4               1                  1            3       4.422    133.0   \n",
       " \n",
       "    click_y  click_quadrant  was_target  target_quadrant  \n",
       " 0    134.0               1           1                1  \n",
       " 1    550.0               3           1                3  \n",
       " 2     68.0               1           1                1  \n",
       " 3    316.0               1           1                1  \n",
       " 4    274.0               1           1                1  ,\n",
       "    participant_id  participant_group  round_index  time_used  targets_total  \\\n",
       " 0               1                  1            1       30.0            112   \n",
       " 1               1                  1            2       30.0            112   \n",
       " 2               1                  1            3       30.0            112   \n",
       " 3               2                  1            1       30.0            112   \n",
       " 4               2                  1            2       30.0            112   \n",
       " \n",
       "    found_total  omissions_total  q1_hits  q2_hits  q3_hits  q4_hits  \\\n",
       " 0           44               68       20       17        7        0   \n",
       " 1           50               62       24        0       26        0   \n",
       " 2           51               61       24        0       23        4   \n",
       " 3           31               81        4        1       26        0   \n",
       " 4           36               76        7       12        4       13   \n",
       " \n",
       "    q1_misses  q2_misses  q3_misses  q4_misses  \n",
       " 0          4          7         31         26  \n",
       " 1          0         34          0         28  \n",
       " 2          0         34          0         27  \n",
       " 3         28         24          7         22  \n",
       " 4         11         16         22         27  )"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "clicks = pd.read_csv(r'D:\\01_Academic\\Disseration\\Post_EXP\\Preprocessing\\Star_cancellation\\Cancellation_Low-Level_Feature_Extraction\\cleaned_cancellation_clicks')\n",
    "results = pd.read_csv(r'D:\\01_Academic\\Disseration\\Post_EXP\\Preprocessing\\Star_cancellation\\Cancellation_Low-Level_Feature_Extraction\\cleaned_cancellation_results')\n",
    "clicks.head(), results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de8fc40",
   "metadata": {},
   "source": [
    "## 1. Compute Omissions per Quadrant\n",
    "Normalize error percentage by arcsin(2 * sqrt(err%)) for each of the four quadrants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "df6d3220",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TommyT\\AppData\\Local\\Temp\\ipykernel_14332\\3072271292.py:9: RuntimeWarning: invalid value encountered in arcsin\n",
      "  norm_err = np.arcsin(2 * np.sqrt(err_pct/100))\n",
      "C:\\Users\\TommyT\\AppData\\Local\\Temp\\ipykernel_14332\\3072271292.py:9: RuntimeWarning: invalid value encountered in arcsin\n",
      "  norm_err = np.arcsin(2 * np.sqrt(err_pct/100))\n",
      "C:\\Users\\TommyT\\AppData\\Local\\Temp\\ipykernel_14332\\3072271292.py:9: RuntimeWarning: invalid value encountered in arcsin\n",
      "  norm_err = np.arcsin(2 * np.sqrt(err_pct/100))\n",
      "C:\\Users\\TommyT\\AppData\\Local\\Temp\\ipykernel_14332\\3072271292.py:9: RuntimeWarning: invalid value encountered in arcsin\n",
      "  norm_err = np.arcsin(2 * np.sqrt(err_pct/100))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>condition</th>\n",
       "      <th>quadrant</th>\n",
       "      <th>err_pct</th>\n",
       "      <th>norm_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Q1</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>0.955317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Q1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Q1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Q1</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Q1</td>\n",
       "      <td>61.111111</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant_id  condition quadrant    err_pct  norm_err\n",
       "0               1          1       Q1  16.666667  0.955317\n",
       "1               1          2       Q1   0.000000  0.000000\n",
       "2               1          3       Q1   0.000000  0.000000\n",
       "3               2          1       Q1  87.500000       NaN\n",
       "4               2          2       Q1  61.111111       NaN"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "om_list = []\n",
    "for q in [1,2,3,4]:\n",
    "    hits   = results[f\"q{q}_hits\"]\n",
    "    misses = results[f\"q{q}_misses\"]\n",
    "    total  = hits + misses\n",
    "\n",
    "    # avoid division by zero\n",
    "    err_pct = np.where(total>0, misses/total*100, np.nan)\n",
    "    norm_err = np.arcsin(2 * np.sqrt(err_pct/100))\n",
    "\n",
    "    dfq = pd.DataFrame({\n",
    "        'participant_id': results['participant_id'],\n",
    "        'condition':      results['round_index'],\n",
    "        'quadrant':       f\"Q{q}\",\n",
    "        'err_pct':        err_pct,\n",
    "        'norm_err':       norm_err\n",
    "    })\n",
    "    om_list.append(dfq)\n",
    "\n",
    "omissions = pd.concat(om_list, ignore_index=True)\n",
    "omissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3759510b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>condition</th>\n",
       "      <th>quadrant</th>\n",
       "      <th>err_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Q1</td>\n",
       "      <td>16.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Q2</td>\n",
       "      <td>29.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Q3</td>\n",
       "      <td>81.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Q4</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Q1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Q2</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Q3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Q4</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Q1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Q2</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Q3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Q4</td>\n",
       "      <td>87.096774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     participant_id  condition quadrant     err_pct\n",
       "0                 1          1       Q1   16.666667\n",
       "51                1          1       Q2   29.166667\n",
       "102               1          1       Q3   81.578947\n",
       "153               1          1       Q4  100.000000\n",
       "1                 1          2       Q1    0.000000\n",
       "52                1          2       Q2  100.000000\n",
       "103               1          2       Q3    0.000000\n",
       "154               1          2       Q4  100.000000\n",
       "2                 1          3       Q1    0.000000\n",
       "53                1          3       Q2  100.000000\n",
       "104               1          3       Q3    0.000000\n",
       "155               1          3       Q4   87.096774"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>quadrant</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>condition</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.635813</td>\n",
       "      <td>82.343137</td>\n",
       "      <td>49.787549</td>\n",
       "      <td>87.967914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72.575163</td>\n",
       "      <td>61.819147</td>\n",
       "      <td>61.709173</td>\n",
       "      <td>58.257919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49.089815</td>\n",
       "      <td>83.981128</td>\n",
       "      <td>46.278650</td>\n",
       "      <td>69.594628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "quadrant          Q1         Q2         Q3         Q4\n",
       "condition                                            \n",
       "1          50.635813  82.343137  49.787549  87.967914\n",
       "2          72.575163  61.819147  61.709173  58.257919\n",
       "3          49.089815  83.981128  46.278650  69.594628"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming you already have:\n",
    "# omissions with columns ['participant_id','condition','quadrant','err_pct','norm_err']\n",
    "\n",
    "# 1) Show the error% per quadrant, per participant & condition\n",
    "display( \n",
    "    omissions[['participant_id','condition','quadrant','err_pct']]\n",
    "    .sort_values(['participant_id','condition','quadrant'])\n",
    "    .head(12)  # just to preview a few rows\n",
    ")\n",
    "\n",
    "# 2) Pivot to a matrix: participants down, quadrants across, within each condition\n",
    "err_by_quad = (\n",
    "    omissions\n",
    "    .pivot_table(\n",
    "        index=['participant_id','condition'],\n",
    "        columns='quadrant',\n",
    "        values='err_pct'\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Preview\n",
    "err_by_quad.head()\n",
    "\n",
    "# 3) (Optionally) get the group‐level mean error% by quadrant for each condition\n",
    "mean_err = (\n",
    "    omissions\n",
    "    .groupby(['condition','quadrant'])['err_pct']\n",
    "    .mean()\n",
    "    .unstack()\n",
    ")\n",
    "mean_err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c50d0c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['participant_id', 'condition', 'err_pct_Q1', 'err_pct_Q2', 'err_pct_Q3', 'err_pct_Q4']\n"
     ]
    }
   ],
   "source": [
    "# === Pivot omissions → one column per quadrant (fixed) ===\n",
    "err_wide = (\n",
    "    omissions\n",
    "    .pivot_table(\n",
    "        index=['participant_id','condition'],\n",
    "        columns='quadrant',\n",
    "        values='err_pct'\n",
    "    )\n",
    "    .reset_index()\n",
    "    # only prefix the actual quadrant columns (Q1–Q4)\n",
    "    .rename(columns={\n",
    "        'Q1': 'err_pct_Q1',\n",
    "        'Q2': 'err_pct_Q2',\n",
    "        'Q3': 'err_pct_Q3',\n",
    "        'Q4': 'err_pct_Q4'\n",
    "    })\n",
    ")\n",
    "\n",
    "# Quick sanity check\n",
    "print(err_wide.columns.tolist())\n",
    "# ['participant_id', 'condition', 'err_pct_Q1', 'err_pct_Q2', 'err_pct_Q3', 'err_pct_Q4']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c817ad8b",
   "metadata": {},
   "source": [
    "## 2. Subjective Epicenter\n",
    "Average (x, y) coordinates of all marks per participant & condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "14394da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks = clicks.rename(columns={\n",
    "    'click_time':'timestamp',\n",
    "    'click_x':'x',\n",
    "    'click_y':'y'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4f52bf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "epicenter = (\n",
    "    clicks\n",
    "    .groupby(['participant_id','round_index'])\n",
    "    .agg(epicenter_x=('x','mean'),\n",
    "         epicenter_y=('y','mean'))\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d7f49e",
   "metadata": {},
   "source": [
    "## 3. First Mark Coordinates\n",
    "Extract the (x, y) of the very first mark (by timestamp) in each participant & condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d331607f",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_mark = (\n",
    "    clicks\n",
    "    .sort_values('timestamp')\n",
    "    .groupby(['participant_id','round_index'])\n",
    "    .first()\n",
    "    .reset_index()[['participant_id','round_index','x','y']]\n",
    "    .rename(columns={'x':'first_x','y':'first_y',\n",
    "                     'round_index':'condition'})\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721e2aa3",
   "metadata": {},
   "source": [
    "## 4. Directional Shifts\n",
    "Compute signed shifts between consecutive marks along x (horizontal) and y (vertical)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "76aea610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_shifts(arr):\n",
    "    diffs = np.diff(arr, prepend=arr[0])\n",
    "    signs = np.where(diffs>0.3,  1,\n",
    "             np.where(diffs< -0.3, -1, 0))\n",
    "    return signs.sum()\n",
    "\n",
    "shifts = (\n",
    "    clicks\n",
    "    .sort_values(['participant_id','round_index','timestamp'])\n",
    "    .groupby(['participant_id','round_index'])\n",
    "    .apply(lambda g: pd.Series({\n",
    "        'hor_shifts': compute_shifts(g['x'].values),\n",
    "        'ver_shifts': compute_shifts(g['y'].values)\n",
    "    }))\n",
    "    .reset_index()\n",
    "    .rename(columns={'round_index':'condition'})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e7b100",
   "metadata": {},
   "source": [
    "## 5. Time Shifts\n",
    "Compute average time interval between consecutive marks per direction type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "068c8f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks['dt'] = clicks.groupby(['participant_id','round_index'])['timestamp'].diff()\n",
    "clicks['h_dir'] = np.where(clicks.groupby(['participant_id','round_index'])['x'].diff()>0,  1,\n",
    "                  np.where(clicks.groupby(['participant_id','round_index'])['x'].diff()<0, -1, np.nan))\n",
    "time_shifts = (\n",
    "    clicks\n",
    "    .dropna(subset=['dt','h_dir'])\n",
    "    .groupby(['participant_id','round_index','h_dir'])['dt']\n",
    "    .mean()\n",
    "    .unstack(fill_value=np.nan)\n",
    "    .reset_index()\n",
    "    .rename(columns={1:'mean_dt_left_to_right', -1:'mean_dt_right_to_left',\n",
    "                     'round_index':'condition'})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7ff120",
   "metadata": {},
   "source": [
    "## 6. Smooth Index\n",
    "Compute the standard deviation of 3-point sliding windows on x and y, then average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "816eeb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_index(vals):\n",
    "    if len(vals)<3:\n",
    "        return np.nan\n",
    "    stds = []\n",
    "    for i in range(len(vals)-2):\n",
    "        stds.append(np.std(vals[i:i+3]))\n",
    "    return np.mean(stds)\n",
    "\n",
    "smooth = (\n",
    "    clicks\n",
    "    .sort_values(['participant_id','round_index','timestamp'])\n",
    "    .groupby(['participant_id','round_index'])[['x','y']]\n",
    "    .apply(lambda df: np.mean([smooth_index(df['x'].values),\n",
    "                               smooth_index(df['y'].values)]))\n",
    "    .reset_index()\n",
    "    .rename(columns={0:'smooth_index','round_index':'condition'})\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758c18eb",
   "metadata": {},
   "source": [
    "## Combine All Features\n",
    "Merge all computed feature tables into a single summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3859b6a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>condition</th>\n",
       "      <th>err_pct_Q1</th>\n",
       "      <th>err_pct_Q2</th>\n",
       "      <th>err_pct_Q3</th>\n",
       "      <th>err_pct_Q4</th>\n",
       "      <th>epicenter_x</th>\n",
       "      <th>epicenter_y</th>\n",
       "      <th>first_x</th>\n",
       "      <th>first_y</th>\n",
       "      <th>hor_shifts</th>\n",
       "      <th>ver_shifts</th>\n",
       "      <th>mean_dt_right_to_left</th>\n",
       "      <th>mean_dt_left_to_right</th>\n",
       "      <th>smooth_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>29.166667</td>\n",
       "      <td>81.578947</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>901.363636</td>\n",
       "      <td>324.681818</td>\n",
       "      <td>220.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.988522</td>\n",
       "      <td>2.494100</td>\n",
       "      <td>67.107726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>467.980000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>227.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.122346</td>\n",
       "      <td>0.198652</td>\n",
       "      <td>56.271532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>87.096774</td>\n",
       "      <td>585.450980</td>\n",
       "      <td>580.764706</td>\n",
       "      <td>468.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.367320</td>\n",
       "      <td>0.430917</td>\n",
       "      <td>57.099812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>21.212121</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>644.677419</td>\n",
       "      <td>746.225806</td>\n",
       "      <td>852.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>-4</td>\n",
       "      <td>8</td>\n",
       "      <td>1.872294</td>\n",
       "      <td>-0.974462</td>\n",
       "      <td>52.573895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>61.111111</td>\n",
       "      <td>57.142857</td>\n",
       "      <td>84.615385</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>1081.444444</td>\n",
       "      <td>467.833333</td>\n",
       "      <td>771.0</td>\n",
       "      <td>609.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.549190</td>\n",
       "      <td>0.520500</td>\n",
       "      <td>49.998429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant_id  condition  err_pct_Q1  err_pct_Q2  err_pct_Q3  err_pct_Q4  \\\n",
       "0               1          1   16.666667   29.166667   81.578947  100.000000   \n",
       "1               1          2    0.000000  100.000000    0.000000  100.000000   \n",
       "2               1          3    0.000000  100.000000    0.000000   87.096774   \n",
       "3               2          1   87.500000   96.000000   21.212121  100.000000   \n",
       "4               2          2   61.111111   57.142857   84.615385   67.500000   \n",
       "\n",
       "   epicenter_x  epicenter_y  first_x  first_y  hor_shifts  ver_shifts  \\\n",
       "0   901.363636   324.681818    220.0    134.0           6           3   \n",
       "1   467.980000   558.000000    227.0    219.0           3           6   \n",
       "2   585.450980   580.764706    468.0     68.0          -3          12   \n",
       "3   644.677419   746.225806    852.0    600.0          -4           8   \n",
       "4  1081.444444   467.833333    771.0    609.0           5          -1   \n",
       "\n",
       "   mean_dt_right_to_left  mean_dt_left_to_right  smooth_index  \n",
       "0              -0.988522               2.494100     67.107726  \n",
       "1              -1.122346               0.198652     56.271532  \n",
       "2              -0.367320               0.430917     57.099812  \n",
       "3               1.872294              -0.974462     52.573895  \n",
       "4              -1.549190               0.520500     49.998429  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = [\n",
    "    err_wide,\n",
    "    epicenter.rename(columns={'round_index':'condition'}),\n",
    "    first_mark,\n",
    "    shifts.rename(columns={'round_index':'condition'}),\n",
    "    time_shifts.rename(columns={'round_index':'condition'}),\n",
    "    smooth.rename(columns={'round_index':'condition'})\n",
    "]\n",
    "\n",
    "feature_summary = dfs[0]\n",
    "for df_ in dfs[1:]:\n",
    "    feature_summary = feature_summary.merge(\n",
    "        df_, on=['participant_id','condition'], how='left'\n",
    "    )\n",
    "\n",
    "feature_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6122bacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved feature summary to D:\\01_Academic\\Disseration\\Post_EXP\\Preprocessing\\Star_cancellation\\Cancellation_High_level_Feature_Extraction\\Cancellation_High-level_Features\n"
     ]
    }
   ],
   "source": [
    "# Save summary\n",
    "outpath = r'D:\\01_Academic\\Disseration\\Post_EXP\\Preprocessing\\Star_cancellation\\Cancellation_High_level_Feature_Extraction\\Cancellation_High-level_Features'\n",
    "feature_summary.to_csv(outpath, index=False)\n",
    "print(f'Saved feature summary to {outpath}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
